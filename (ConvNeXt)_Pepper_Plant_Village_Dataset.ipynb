{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1SXEyPsWrxb6w_Zzuj1_L_o7mlz9zj_lT",
      "authorship_tag": "ABX9TyPUO+h7LDZgbh1IJn4QmRsy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnandDaksh/Crop-Disease-Classification/blob/main/(ConvNeXt)_Pepper_Plant_Village_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OPsRUAefCeu",
        "outputId": "16c06ddc-3740-4ac1-87ee-78747789dc22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "\n",
        "# Define ConvNeXt architecture manually\n",
        "class ConvNeXt(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ConvNeXt, self).__init__()\n",
        "\n",
        "        # Define the layers of the network\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(256 * 32 * 32, 1024)\n",
        "        self.fc2 = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define the forward pass\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Define dataset directory\n",
        "dataset_dir = \"/content/drive/MyDrive/Plant Village Datasets/Pepper\"\n",
        "\n",
        "# Define classes\n",
        "classes = [\"Pepper__bell___Bacterial_spot\", \"Pepper__bell___healthy\"]\n",
        "\n",
        "# Merge train and test directories into one folder\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        for class_idx, class_name in enumerate(classes):\n",
        "            class_dir = os.path.join(root_dir, class_name)\n",
        "            for img_name in os.listdir(class_dir):\n",
        "                img_path = os.path.join(class_dir, img_name)\n",
        "                self.images.append(img_path)\n",
        "                self.labels.append(class_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "dataset = CustomDataset(root_dir=dataset_dir, transform=transform)\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Define data loaders with the same batch size\n",
        "batch_size = len(train_dataset)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "# Create ConvNeXt model\n",
        "num_classes = len(classes)  # Adjust num_classes\n",
        "model = ConvNeXt(num_classes=2)\n",
        "\n",
        "\n",
        "\n",
        "# Create ConvNeXt model\n",
        "model = ConvNeXt(num_classes=len(classes))\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Reshape outputs and labels\n",
        "        outputs_flat = outputs.view(-1, num_classes)\n",
        "        labels_flat = labels.view(-1)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(outputs_flat, labels_flat)\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Test the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "predictions = []\n",
        "true_labels = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        predictions.extend(predicted.tolist())\n",
        "        true_labels.extend(labels.tolist())\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Accuracy on test set: {accuracy:.2%}\")\n",
        "\n",
        "# Plot confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predictions)\n",
        "accuracy_percentage = accuracy * 100\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(f'Predicted labels\\nAccuracy: {accuracy_percentage:.2f}%')\n",
        "plt.ylabel(f'True labels\\nAccuracy: {accuracy_percentage:.2f}%')\n",
        "plt.title(f'Confusion Matrix\\nAccuracy: {accuracy_percentage:.2f}%')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ej80azaRhWfp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}